---
layout: post
title: "Geminiで長時間の動画を処理させるコツ：分割とパラメータ最適化の戦略"
date: 2026-01-15
excerpt: "Geminiで45分を超える長尺動画を扱う際の制限事項と、文脈を維持しながら分割・処理するための具体的な戦略について解説します。"
category: "Research"
---

動画検索システムの構築において、Gemini（Vertex AI）を活用した動画のメタデータ抽出は非常に強力な手法です。しかし、実運用では「45分の壁」という技術的な制約に直面することがあります。

本稿では、仕様上の上限を超える長尺動画を処理する際の「分割のコツ」と「パラメータ最適化」について、具体的な実装戦略を提案します。

---

### 1. Geminiの動画処理における「45分の壁」

Google Cloudのドキュメントによれば、現状のVertex AI Gemini APIにおける動画入力の制限は以下の通りです。

- **音声あり動画**: 約45分まで
- **音声なし動画**: 約1時間まで

これを1秒あたり1フレーム（1fps）のサンプリングレートで見ると、45分は2,700トークンに相当する画像情報（および音声情報）を含むことになります。これらの制限は、モデルのコンテキストウィンドウというよりも、API側の入力ペイロードやストリーミング処理の仕様に起因する側面が大きいです。

### 2. 動画分割：単なる「半分」ではいけない理由

45分を超える動画を処理する場合、動画ファイルを分割して複数回処理することになりますが、単純に「0〜45分」「45〜90分」のように分割すると、境界線で会話や文脈が分断されるリスクがあります。これを防ぐための2つの重要戦略を紹介します。

#### A: 5分程度のオーバーラップを設ける
境界付近の文脈を保持するため、セグメント間に重なりを持たせることが不可欠です。

- **1処理目**: 0分 〜 45分 (実際の処理: 0-45分)
- **2処理目**: 40分 〜 85分 (実際の処理: 40-85分)
このように、前パートの末尾5分程度を次パートの冒頭に含めることで、イベントの分断を防ぎます。

#### B: 「Chain of Context」：前パートのメタデータを次パートのプロンプトに注入
より高度な手法として、1パート目の処理で抽出されたメタデータ（サマリーなどのテキスト情報）を、2パート目のAPIコール時のプロンプトに含める方法が有効です。

![][image2]

動画データそのものを渡すのは重いですが、テキスト情報に圧縮して伝えることで、前パートの状況を「コンテキスト（背景知識）」としてモデルに引き継ぎ、一貫した理解が可能になります。

### 3. メタデータの抽出と統合（Map-Reduceアプローチ）

分割して抽出したデータをどのように統合すべきでしょうか。以下の2つのステップを推奨します。

1.  **各セグメントの個別抽出 (Map)**: 各セグメントに対して、特定のタイムスタンプごとのイベント、キーワード、サマリーを抽出させます。
2.  **サマリーの統合サマリー (Reduce)**: 全セグメントのメタデータが出揃った後、抽出されたテキストデータのみをGemini（1.5 Proなど）に入力し、全体のタイムラインを再構築させます。

この「情報の要約をさらに要約する」アプローチにより、動画全体を一貫したコンテキストで検索対象にすることが可能になります。

### 4. APIのパラメータ最適化アプローチ

動画の性質や目的に応じて、以下のパラメータを調整することで処理効率と精度をコントロールできます。

#### A: FPS調整と速度のトレードオフ
読み込ませる動画の FPS を増やす（動画の速度を上げる）ことで、45分の中でより多くの情報を処理させることができます。ただし、FPS を上げると、動きの激しい動画だと精度が落ちる場合もあります。講義動画などは、板書のスピードは速くないので、有効な可能性があります。
（参考：[動画の理解 | Gemini API](https://ai.google.dev/gemini-api/docs/video-understanding?hl=ja)）

> 長い動画の場合は、FPS を低く（1 未満）設定することをおすすめします。この機能は、ほとんど静止している動画（講義など）に特に役立ちます。

#### B: 解像度の最適化によるスピードアップ
動画の解像度を下げることで、処理スピード自体を上げることが可能です。Geminiは低解像度でも高い認識精度を維持できるため、メタデータ抽出などのタスクでは、転送コストとスピードのトレードオフとして非常に有効な手段です。
（参考：[Gemini 1.5 Pro/Flashの動画解析におけるトークン消費量と制約](https://tech-tech.nddhq.co.jp/2025/09/24/gemini-tokens-on-video-analysis/#)）

### まとめ

45分超えの動画をGeminiで処理する際は、**「適切なオーバーラップとコンテクストの連鎖」**、そして**「動画の性質に合わせたFPS・解像度の最適化」**が鍵となります。

単なる結合ではなく、境界の文脈を維持しつつ、計算リソースを最適に配分する工夫を実装に盛り込むことで、実用的で高度な動画検索システムの基盤を構築できるはずです。

#### **Works cited**

[1] 動画理解 | Generative AI on Vertex AI | Google Cloud Documentation [https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/video-understanding)

[2] Use the Gemini API for Video Analysis | Gemini API | Google for Developers [https://ai.google.dev/gemini-api/docs/video](https://ai.google.dev/gemini-api/docs/video)

[image1]: ../media/blog/gemini-video-tips/overlap-strategy.png
[image2]: ../media/blog/gemini-video-tips/context-chain.png
